{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELO and Wine Ratings\n",
    "\n",
    "Whether it be Uber, Amazon or Google, star ratings are everywhere we look these days.\n",
    "\n",
    "For all their simplicity, they suffer from a range of problems. To name some: overrepresentation of extreme views in an average rating, different standards across users for what constitutes good/bad and anchoring effects of existing ratings. \n",
    "\n",
    "So is there an alternative? Well, maybe. In this analysis we are going to explore whether we can borrow from the game of chess to come up with a new type of wine rating - a variation of the ELO score used to evaluate the relative strength of chess players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "import psycopg2\n",
    "from wine_elo import wine_data_cleanup as wdc\n",
    "# from chessratings import uscf_elo\n",
    "# import wine_data_cleanup as wdc\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.transforms\n",
    "\n",
    "pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First off, we need a dataset to work with. Wine rating app Vivino has been collecting star ratings for wines from its users for years. We have scraped all the wine reviews by the top 2,500 Vivino users in the Netherlands (see web_scraper.py for details).\n",
    "\n",
    "The output files from our web scraper are JSONs. We will combine these JSONs into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't subtract offset-naive and offset-aware datetimes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/guillaume/P/WineELO/wine_elo.ipynb Cell 4\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m all_wine_reviews \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m rows:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     u \u001b[39m=\u001b[39m {\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mwine_id\u001b[39m\u001b[39m'\u001b[39m: r[\u001b[39m0\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mreviewer\u001b[39m\u001b[39m'\u001b[39m: r[\u001b[39m1\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mreview_date\u001b[39m\u001b[39m'\u001b[39m: r[\u001b[39m2\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mrating\u001b[39m\u001b[39m'\u001b[39m: r[\u001b[39m3\u001b[39m], \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mvintage\u001b[39m\u001b[39m'\u001b[39m: r[\u001b[39m4\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mwine_name\u001b[39m\u001b[39m'\u001b[39m: r[\u001b[39m5\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mproducer\u001b[39m\u001b[39m'\u001b[39m: r[\u001b[39m6\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mregion_name\u001b[39m\u001b[39m'\u001b[39m: r[\u001b[39m7\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mscrape_date\u001b[39m\u001b[39m'\u001b[39m: datetime\u001b[39m.\u001b[39mnow(),\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mreview_time_ago\u001b[39m\u001b[39m'\u001b[39m: datetime\u001b[39m.\u001b[39;49mnow() \u001b[39m-\u001b[39;49m datetime\u001b[39m.\u001b[39;49mfromisoformat(r[\u001b[39m2\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         }\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     all_wine_reviews\u001b[39m.\u001b[39mappend(u)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#W3sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m wine_review_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mjson_normalize(all_wine_reviews)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't subtract offset-naive and offset-aware datetimes"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(\n",
    "    dbname=\"sommsense\",\n",
    "    user=\"user\",\n",
    "    password=\"password\",\n",
    "    host=\"sommsense-mini\"\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "try:\n",
    "    cur.execute(\"\"\"\n",
    "    SELECT vr.wine_id, vr.reviewer_id, vr.review_date, vr.rating, vr.year,\n",
    "    vw.name, vwr.name, r.name\n",
    "    FROM vivino_reviews vr\n",
    "    INNER JOIN vivino_wines vw ON vr.wine_id = vw.id\n",
    "    INNER JOIN vivino_wineries vwr ON vwr.id = vw.winery_id\n",
    "    INNER JOIN vivino_regions r ON r.id = vw.region_id\n",
    "    WHERE year is not null LIMIT 20\n",
    "    \"\"\")\n",
    "except psycopg2.Error as e:\n",
    "    print(\"Unable to execute query\")\n",
    "    print(e)\n",
    "rows = cur.fetchall()\n",
    "\n",
    "\n",
    "all_wine_reviews = []\n",
    "for r in rows:\n",
    "    u = {\n",
    "        'wine_id': r[0],\n",
    "        'reviewer': r[1], \n",
    "        'review_date': r[2], \n",
    "        'rating': r[3], \n",
    "        'vintage': r[4],\n",
    "        'wine_name': r[5],\n",
    "        'producer': r[6],\n",
    "        'region_name': r[7],\n",
    "        'scrape_date': datetime.now(),\n",
    "        'review_time_ago': datetime.now() - datetime.fromisoformat(r[2]).replace(tzinfo=None)\n",
    "        }\n",
    "    \n",
    "    all_wine_reviews.append(u)\n",
    "\n",
    "wine_review_df = pd.json_normalize(all_wine_reviews)\n",
    "wine_review_df = wine_review_df[['wine_id', 'reviewer', 'review_date', 'review_time_ago', 'scrape_date', 'rating', 'vintage', 'wine_name', 'producer', 'region_name']]\n",
    "wine_review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our raw dataset consists of ~1 million wine reviews, with one row for each. A wine ID is defined for each wine and vintage (the same wine from different vintages will have different IDs). The review_date, review_time_ago and scrape_date columns are the raw data inputs we will need to determine when exactly a rating was given, since the review_date column does not include year. The star rating (out of 5) is captured in the rating column. The remaining columns include metadata about the wine (wine_name, producer, region_name, country_name). \n",
    "\n",
    "We can now use our raw datafile to create two tables: \n",
    "\n",
    "1. A table containing wine metadata that we can use to slice and dice our results later on\n",
    "2. A table we can use to feed data into our ELO algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vintage</th>\n",
       "      <th>wine_name</th>\n",
       "      <th>producer</th>\n",
       "      <th>region_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wine_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2659163</th>\n",
       "      <td>2017</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Bleeding Heart</td>\n",
       "      <td>McLaren Vale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076905</th>\n",
       "      <td>2017</td>\n",
       "      <td>Strawberry Fields Rosé</td>\n",
       "      <td>Evans &amp; Tate</td>\n",
       "      <td>Margaret River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6001577</th>\n",
       "      <td>2016</td>\n",
       "      <td>Hullabaloo Shiraz</td>\n",
       "      <td>Evans &amp; Tate</td>\n",
       "      <td>Margaret River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5378534</th>\n",
       "      <td>2016</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Bleeding Heart</td>\n",
       "      <td>Lower Murray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137662</th>\n",
       "      <td>2013</td>\n",
       "      <td>Bin 0703 Shiraz</td>\n",
       "      <td>Lindeman's</td>\n",
       "      <td>Hunter Valley</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        vintage               wine_name        producer     region_name\n",
       "wine_id                                                                \n",
       "2659163    2017         Sauvignon Blanc  Bleeding Heart    McLaren Vale\n",
       "4076905    2017  Strawberry Fields Rosé    Evans & Tate  Margaret River\n",
       "6001577    2016       Hullabaloo Shiraz    Evans & Tate  Margaret River\n",
       "5378534    2016      Cabernet Sauvignon  Bleeding Heart    Lower Murray\n",
       "1137662    2013         Bin 0703 Shiraz      Lindeman's   Hunter Valley"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_metadata = wine_review_df[['wine_id', 'vintage', 'wine_name', 'producer', 'region_name']].drop_duplicates()\n",
    "wine_metadata.set_index('wine_id', inplace=True)\n",
    "wine_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can proceed with our second table. We first need to do some cleanup. \n",
    "\n",
    "We want a simplified table that contains one row per wine review, with only the necessary information about that review (the reviewer, review date and the rating out of 5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'review_time_ago'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wine_elo/lib/python3.11/site-packages/pandas/core/indexes/base.py:3080\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3080\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3081\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:70\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:101\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:4554\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:4562\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'review_time_ago'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/guillaume/P/WineELO/wine_elo.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m wine_reviews_cleaned \u001b[39m=\u001b[39m wdc\u001b[39m.\u001b[39;49mclean_wine_reviews(wine_review_df)\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mwine_id\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mreset_index()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m wine_reviews_cleaned\u001b[39m.\u001b[39mdrop_duplicates(inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/guillaume/P/WineELO/wine_elo.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m wine_reviews_cleaned\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mwine_id\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/P/WineELO/wine_elo/wine_data_cleanup.py:588\u001b[0m, in \u001b[0;36mclean_wine_reviews\u001b[0;34m(review_df)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclean_wine_reviews\u001b[39m(review_df):\n\u001b[0;32m--> 588\u001b[0m     review_df[\u001b[39m'\u001b[39m\u001b[39mfinal_review_date\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m review_df\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: compute_date(\n\u001b[1;32m    589\u001b[0m         x[\u001b[39m'\u001b[39;49m\u001b[39mscrape_date\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mreview_date\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mreview_time_ago\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m    591\u001b[0m     \u001b[39m# drop any reviews that don't have a vintage specified. N.V. is acceptable, but blank vintage is not.\u001b[39;00m\n\u001b[1;32m    592\u001b[0m     review_df[\u001b[39m'\u001b[39m\u001b[39mvintage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreplace({\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mnan}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wine_elo/lib/python3.11/site-packages/pandas/core/frame.py:7768\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7757\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   7759\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   7760\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   7761\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   7766\u001b[0m     kwds\u001b[39m=\u001b[39mkwds,\n\u001b[1;32m   7767\u001b[0m )\n\u001b[0;32m-> 7768\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wine_elo/lib/python3.11/site-packages/pandas/core/apply.py:185\u001b[0m, in \u001b[0;36mFrameApply.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    183\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> 185\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wine_elo/lib/python3.11/site-packages/pandas/core/apply.py:276\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 276\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    278\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    279\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wine_elo/lib/python3.11/site-packages/pandas/core/apply.py:290\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    288\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    289\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> 290\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    291\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    292\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    293\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    294\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/P/WineELO/wine_elo/wine_data_cleanup.py:589\u001b[0m, in \u001b[0;36mclean_wine_reviews.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclean_wine_reviews\u001b[39m(review_df):\n\u001b[1;32m    588\u001b[0m     review_df[\u001b[39m'\u001b[39m\u001b[39mfinal_review_date\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m review_df\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: compute_date(\n\u001b[0;32m--> 589\u001b[0m         x[\u001b[39m'\u001b[39m\u001b[39mscrape_date\u001b[39m\u001b[39m'\u001b[39m], x[\u001b[39m'\u001b[39m\u001b[39mreview_date\u001b[39m\u001b[39m'\u001b[39m], x[\u001b[39m'\u001b[39;49m\u001b[39mreview_time_ago\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    591\u001b[0m     \u001b[39m# drop any reviews that don't have a vintage specified. N.V. is acceptable, but blank vintage is not.\u001b[39;00m\n\u001b[1;32m    592\u001b[0m     review_df[\u001b[39m'\u001b[39m\u001b[39mvintage\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mreplace({\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m: np\u001b[39m.\u001b[39mnan}, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wine_elo/lib/python3.11/site-packages/pandas/core/series.py:853\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    850\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    852\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 853\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    855\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wine_elo/lib/python3.11/site-packages/pandas/core/series.py:961\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m    960\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m--> 961\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m    962\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/envs/wine_elo/lib/python3.11/site-packages/pandas/core/indexes/base.py:3082\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3081\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3082\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3084\u001b[0m \u001b[39mif\u001b[39;00m tolerance \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3085\u001b[0m     tolerance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_convert_tolerance(tolerance, np\u001b[39m.\u001b[39masarray(key))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'review_time_ago'"
     ]
    }
   ],
   "source": [
    "\n",
    "wine_reviews_cleaned = wdc.clean_wine_reviews(wine_review_df).set_index('wine_id').reset_index()\n",
    "wine_reviews_cleaned.drop_duplicates(inplace=True)\n",
    "wine_reviews_cleaned.set_index('wine_id', inplace=True)\n",
    "\n",
    "wine_reviews_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for a closer look at these reviews. Can we learn anything about how these star ratings are distributed by reviewer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_distro = wine_reviews_cleaned.groupby('reviewer').agg({'rating': ['describe']})\n",
    "plot_series = reviewer_distro[('rating', 'describe', 'mean')]\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(plot_series, weights=np.zeros_like(plot_series) + 1/plot_series.size, bins=30, color='lightslategray')\n",
    "plt.title('Average Reviewer Rating, Relative Frequency', fontsize=14)\n",
    "plt.ylabel('Proportion of Reviewers', fontsize=12)\n",
    "plt.xlabel('Average Rating', fontsize=12)\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()]) \n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(plot_series, weights=np.zeros_like(plot_series) + 1/plot_series.size, bins=100, color='steelblue', cumulative=True)\n",
    "plt.title('Average Reviewer Rating, Cumulative Frequency', fontsize=14)\n",
    "plt.ylabel('Cumulative Proportion of Reviewers', fontsize=12)\n",
    "plt.xlabel('Average Rating', fontsize=12)\n",
    "plt.grid(color='lightgrey', linestyle='-', axis='y')\n",
    "plt.ylim(0, 1)\n",
    "plt.yticks(np.arange(0.0, 1.0, 0.1))\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()]) \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This view of the data confirms some of the shortcomings of a system based on star ratings - most importantly that reviewers apply the star rating scale differently. Our dataset supports this, despite consisting of a group of reviewers that is geographically (and likely culturally) relatively homogenous. The 10% most critical reviewers award wines with less than 3.3/5 points, on average. The 10% most generous reviewers give upwards of 4/5 points on average. \n",
    "\n",
    "While it is possible that more critical reviewers are simply drinking worse wines, this is unlikely to explain for the entirety of the variance here. It stands to reason that some people simply give lower or higher ratings to wines, on average. This has a bearing on average wine ratings also. If a wine has been rated by generous individuals, it will have a higher score than if it has been rated by more critical users.\n",
    "\n",
    "\n",
    "### From a star rating to ELO\n",
    "\n",
    "We're almost ready to compute our ELO scores. We still, however, need to introduce a few key concepts and do a couple more data transformations. \n",
    "\n",
    "ELO scores are normally used to model skill levels in zero-sum games, most famously in chess. The difference in ratings between chess players serves as an indicator for who is more likely to win a match. Each match has one of three possible outcomes: win, draw or loss. Both players' scores are adjusted after a match based on the actual vs. expected outcome. Players will often compete in tournaments that consist of several matches. Here, score updates are typically done after a tournament has been conducted rather than after each individual match. \n",
    "\n",
    "We can circumvent many of the problems that plague star rating systems by framing a *reviewer's individual ratings on a given day* as a tournament of zero-sum matches. For this purpose, let us propose the following definitions:\n",
    "\n",
    "- **Player**: a specific wine from a specific vintage\n",
    "- **Match**: a head-to-head zero-sum comparison of two wines reviewed on a specific day by a specific individual\n",
    "- **Tournament**: the collection of head-to-head matches by a specific individual on a specific day\n",
    "\n",
    "The structure above relies on the basic assumption that we can trust a person to be ordinally consistent in the way they rank wines on a given day. If they give one wine 4 stars and another wine 5 on a given day, we can deduce that the 5-star wine was better than the 4-star one. \n",
    "\n",
    "#### Example\n",
    "\n",
    "A hypothetical example to illustrate:\n",
    "\n",
    "Reviewer John reviewed 3 different wines on May 20th, 2021: A, B and C.\n",
    "\n",
    "- A: 5 stars\n",
    "- B: 4 stars\n",
    "- C: 4 stars\n",
    "\n",
    "As a head-to-head zero sum game these results would look as follows:\n",
    "\n",
    "- A vs. B: A wins, B loses\n",
    "- A vs. C: A wins, C loses\n",
    "- B vs. C: Draw\n",
    "\n",
    "These three head-to-head **matches** can be grouped together in a **tournament**. We will run these tournaments chronologically. A wine (**player**) that has not participated in a tournament yet will receive a newly initialized ELO score, while a wine that has participated in tournaments in the past will enter a new tournament with its most recent ELO score. \n",
    "\n",
    "As we run each tournament, we will store information about each in a lookup table. This will allow us to study how wine ELO scores have evolved over time.\n",
    "\n",
    "\n",
    "#### Quick note on ELO scores\n",
    "\n",
    "Before we dive in, it is worth pointing out which implementation of the ELO algorithm we are using. We are using the most recent (2021) rules used by the US Chess Federation (USCF) as captured in the chessratings package.\n",
    "\n",
    "Wines that are unrated (i.e. have not participated in any tournaments yet) are initialized with an ELO score of 1300, as would be the case for any adults above the age of 26 in the USCF rating scheme.  \n",
    "\n",
    "Alright, enough explanation! Let's run the tournaments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# score lookup table will store information about player performance that we need to initialize ratings as we run tournaments.\n",
    "score_lookup_table_columns = ['wine_id', 'tournament_date', 'tournament_number', 'elo_rating', 'nr_games_played', 'nr_wins', 'nr_losses', 'reviewer']\n",
    "score_lookup_table = pd.DataFrame(columns=score_lookup_table_columns)\n",
    "all_results = wdc.run_tournaments(wine_reviews_cleaned, score_lookup_table)\n",
    "all_results.to_csv('all_results.csv')\n",
    "all_results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better manage some of the volatility we may see in ELO scores, we will additionally compute a moving average (MA) ELO score, with a trailing window of 5 tournaments. This will allow us to smooth out the effect of individual tournaments skewing the score for any one wine, while preserving the ability to have wine scores trend up or down over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['ma_elo'] = all_results.groupby('wine_id')['elo_rating'].transform(lambda x: x.rolling(5, 1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our MA ELO scores over time, we can start to explore the results. First, let's produce an overview of all the most recent MA ELO scores, by wine. We will eliminate any wines that have only competed in a handful of tournaments and matches.\n",
    "\n",
    "The USCF can help here with a definition of what constitutes an 'established' rating: at least 25 matches. We will layer on top of this a minimum number of tournaments that we will require eligible wines to have competed in, to reduce the potential impact of a single user rating a wine very highly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_by_wines = all_results.groupby('wine_id').agg({'tournament_date': 'max', 'nr_games_played': 'sum', 'nr_wins': 'sum', 'nr_draws': 'sum', 'nr_losses': 'sum', 'tournament_number': 'max'}).reset_index()\n",
    "group_by_wines = pd.merge(group_by_wines, all_results[['wine_id', 'tournament_date', 'elo_rating', 'ma_elo']], how='left', on=['wine_id', 'tournament_date']).drop_duplicates(subset=['wine_id'])\n",
    "\n",
    "group_by_wines = pd.merge(group_by_wines, wine_metadata, left_on='wine_id', right_index=True).drop_duplicates(subset=['wine_id'])\n",
    "group_by_wines = group_by_wines[['wine_id', 'vintage', 'tournament_date', 'elo_rating', 'ma_elo', 'tournament_number', 'nr_games_played', 'nr_wins', 'nr_draws', 'nr_losses', 'wine_name', 'producer', 'region_name', 'country_name']]\n",
    "group_by_wines['nr_draws'] = group_by_wines['nr_draws'].astype(int)\n",
    "\n",
    "group_by_wines_bounded = group_by_wines.loc[(group_by_wines['tournament_number'] >= 10) & (results_grouped['nr_games_played'] >= 25)]\n",
    "group_by_wines_bounded.sort_values(by=['ma_elo'], ascending=False).head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ding ding! We have a winner! The 2017 Reserve Chenin Blanc by DeMorgenzon in Stellenbosch, South Africa. This wine has participated in 22 valid tournaments and has competed against a total of 180 other wines. Its moving average ELO is currently 2513, putting it well above the other wines in our dataset. \n",
    "\n",
    "Now, let's take a look at how our ELO metric compares to the star ratings that this wine has received. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def retrieve_last_rating(wine_id, tournament_number):\n",
    "    historical_ratings = all_results.loc[(all_results['tournament_number'] < tournament_number) & (all_results['wine_id'] == wine_id)]\n",
    "    most_recent_rating = historical_ratings.loc[historical_ratings['tournament_number'] == max(historical_ratings['tournament_number'])].reset_index()\n",
    "    most_recent_rating = most_recent_rating.at[0, 'elo_rating']\n",
    "    return most_recent_rating\n",
    "\n",
    "def score_head_to_head(rating, opponent_rating):\n",
    "    if rating > opponent_rating:\n",
    "        score = 1\n",
    "    elif rating == opponent_rating:\n",
    "        score = 0.5\n",
    "    elif rating < opponent_rating:\n",
    "        score = 0\n",
    "    else:\n",
    "        score = None\n",
    "    return score\n",
    "\n",
    "wine_id = '152394404'\n",
    "\n",
    "wine_results = all_results.loc[all_results['wine_id'] == wine_id]\n",
    "tournament_results = []\n",
    "for index, row in wine_results.iterrows():\n",
    "    tournament_result = all_results.loc[(all_results['reviewer'] == row['reviewer']) & (all_results['tournament_date'] == row['tournament_date'])]\n",
    "    # retrieve the main wine's rating\n",
    "    reviewer_date_ratings = wine_reviews_cleaned.loc[(wine_reviews_cleaned['final_review_date'] == row['tournament_date']) & (wine_reviews_cleaned['reviewer'] == row['reviewer'])]\n",
    "    wine_rating = reviewer_date_ratings.at[wine_id, 'rating']\n",
    "    for i, r in tournament_result.iterrows():\n",
    "        if r['tournament_number'] > 1:\n",
    "            opponent_initialized_elo = retrieve_last_rating(r['wine_id'], r['tournament_number'])\n",
    "        else:\n",
    "            opponent_initialized_elo = 1300\n",
    "        opponent_star_rating = reviewer_date_ratings.at[r['wine_id'], 'rating']\n",
    "        if isinstance(opponent_star_rating, float):\n",
    "            score = score_head_to_head(wine_rating, opponent_star_rating)\n",
    "            tournament_result_details = [row['tournament_number'], r['wine_id'], row['reviewer'], row['tournament_date'], opponent_initialized_elo, score]\n",
    "            tournament_results.append(tournament_result_details)\n",
    "\n",
    "tr = pd.DataFrame(tournament_results, columns=['tournament_number', 'wine_id', 'reviewer', 'tournament_date', 'initialized_elo', 'score'])\n",
    "opponents = tr.loc[tr['wine_id'] != wine_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "colors = {0.0: 'lightcoral', 0.5: 'khaki', 1.0: 'darkseagreen'}\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_ticks(np.arange(min(opponents['tournament_number']) - 0.5, max(opponents['tournament_number']) + 1.5, 1.0))\n",
    "ax.set_xticklabels(np.arange(1, max(opponents['tournament_number'])+2, 1), fontsize=12)\n",
    "ax.grid(axis='x', linestyle='--')\n",
    "\n",
    "ax.scatter(opponents['tournament_number'], opponents['initialized_elo'], c=opponents['score'].map(colors), label='Opponent ELO (Green=Win, Yellow=Draw, Red=loss')\n",
    "\n",
    "ma_elo_shifted = [np.nan] * 4 + list(wine_results['ma_elo'])[4:]\n",
    "ax.plot([i +1 for i in list(wine_results['tournament_number'])], ma_elo_shifted, color='lightgrey', label='MA (5) ELO')\n",
    "\n",
    "main_elo_series = [1300] + list(wine_results['elo_rating'])\n",
    "main_elo_series_tr = [1] + [1+ i for i in list(wine_results['tournament_number'])]\n",
    "ax.scatter(main_elo_series_tr, main_elo_series, color='black', label='ELO, 2017 DeMorgenzon Chenin Blanc')\n",
    "\n",
    "dx = 25/72.; dy = 0/72. \n",
    "offset = matplotlib.transforms.ScaledTranslation(dx, dy, fig.dpi_scale_trans)\n",
    "for label in ax.xaxis.get_majorticklabels():\n",
    "    label.set_transform(label.get_transform() + offset)\n",
    "\n",
    "plt.xlabel('Tournament Number', fontsize=12)\n",
    "plt.ylabel('ELO score', fontsize=12)\n",
    "plt.ylim(0, 3000)\n",
    "\n",
    "ax.legend(loc='lower right', fontsize=12)\n",
    "plt.title('2017 DeMorgenzon Chenin Blanc, ELO over time', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above illustrates how the ELO score of our DeMorgenzon Chenin Blanc (black dots) evolved over the course of the 22 tournaments that it competed in. The colored dots indicate the ELO scores of the wines it competed against, with the color of the dot indicating the result of the head-to-head match: (green=win, yellow=draw, red=loss). \n",
    "\n",
    "In tournament 1, it was initialized with an ELO of 1300, as is the case for all unrated wines. The green dots indicate that it won all its matches in that tournament, and that its rating subsequently increased to about 2100. \n",
    "\n",
    "Let's take a closer look at the second tournament it participated in to get a deeper understanding for the dynamics between star rating and ELO. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tournament_2_opponents = opponents.loc[opponents['tournament_number'] == 2]\n",
    "tournament_2_wine_info = tr.loc[(tr['wine_id'] == wine_id) & (tr['tournament_number'] == 2)]\n",
    "\n",
    "tournament_2_details = pd.concat([tournament_2_opponents, tournament_2_wine_info])\n",
    "tournament_2_details = pd.merge(tournament_2_details, wine_reviews_cleaned, left_on=['wine_id', 'reviewer', 'tournament_date'], right_on=['wine_id', 'reviewer', 'final_review_date'])\n",
    "tournament_2_details = pd.merge(tournament_2_details, wine_metadata, on='wine_id', how='left').drop_duplicates(subset='wine_id')\n",
    "\n",
    "tournament_2_details[['wine_id', 'reviewer', 'initialized_elo', 'rating', 'wine_name', 'vintage', 'producer']].sort_values('rating', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our DeMorgenzon Chenin Blanc entered tournament 2 with an ELO rating of 2126. It faced 10 other wines, ranging in ELO between 1222 and 2283. It received a star rating of 4.5, higher than any other wine competing in the tournament. This translated into 10 outright wins and another jump in ELO rating to 2683. \n",
    "\n",
    "The rating jump (+553) here is high for a few specific reasons - firstly, our winning wine entered the tournament having only previously competed in 11 matches (tournament 1), and won all of these. As a consequence of the small sample size combined with a streak of only wins, the ELO rating algorithm - as per the specifications of the US Chess Federation - uses a 'special rating' formula to compute the rating adjustment. This special rating formula results in higher potential jumps, since it is used in situations where there is more uncertainty around a player's rating. The second reason the jump was so big is because our Chenin Blanc defeated the 2017 di Lenardo Thanks Bianco, a wine that had an ELO rating of 2283 at the time. Defeating players that are much stronger can result in bigger jumps in ELO. \n",
    "\n",
    "Before we move on, let's take a look at the reviewer responsible for tournament 2. Our winning wine was given a star rating of 4.5 - but how exceptional was this really?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_details = wine_reviews_cleaned.loc[wine_reviews_cleaned['reviewer'] == '10523344']\n",
    "print('Average star rating by reviewer 10523344:', np.mean(reviewer_details['rating']))\n",
    "\n",
    "reviewer_details = pd.merge(wine_reviews_cleaned['rating'].value_counts(normalize=True), reviewer_details['rating'].value_counts(normalize=True), left_index=True, right_index=True, how='left').reset_index()\n",
    "reviewer_details.columns = ['star_rating', 'all_reviews', 'reviewer_10523344']\n",
    "\n",
    "reviewer_details.sort_values('star_rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This output demonstrates that the reviewer in tournament 2 is generally more pessimistic than most other reviewers in our dataset. Their average rating is just shy of 3.4 stars. Looking back to our reviewer distribution earlier in this notebook, this puts this reviewer in the 20% most critical reviewers. This is further supported by the fact that only 2% of their ratings are 4.5 stars or above. In contrast, when looking across the ~1 million reviews in our *full* dataset, we can see that almost 13% of ratings given to wines are 4.5 stars or above. \n",
    "\n",
    "We can conclude that the star rating system doesn't really do justice to how highly our Chenin Blanc was assessed in tournament 2. Our ELO score, on the other hand, is able to control for reviewer 'strictness', and therefore generate a big lift in score as a result of this exceptional performance.\n",
    "\n",
    "Our ELO score additionally controls for differences in how individual reviewers may apply ratings over time (becoming less/more strict). It only requires that reviewers are ordinally consistent with their wine ratings on a single day. ELO is also better able to capture changes in a wine's quality over time than an average star rating over the full lifetime of a wine. As a wine ages and gets better/worse, its ELO will evolve to reflect this.\n",
    "\n",
    "It does appear that our ELO score addresses some fundamental issues that plague star ratings. So how should we use it? Let's take a step back and look at the difference between ELO and star ratings for *all* the wines in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_and_scores = pd.merge(all_results, wine_reviews_cleaned, left_on=['reviewer', 'wine_id', 'tournament_date'], right_on=['reviewer', 'wine_id', 'final_review_date']).drop_duplicates(subset=['wine_id', 'tournament_number'])\n",
    "average_ratings = reviews_and_scores.groupby('wine_id')['rating'].mean().reset_index()\n",
    "elo_vs_rating = pd.merge(average_ratings, group_by_wines_bounded, on='wine_id')\n",
    "\n",
    "x = elo_vs_rating['ma_elo']\n",
    "y = elo_vs_rating['rating']\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(x, y, color='lightgrey')\n",
    "plt.plot(np.unique(x), np.poly1d(np.polyfit(x, y, 1))(np.unique(x)))\n",
    "plt.title('Moving Average ELO vs Star rating', fontsize=16)\n",
    "plt.xlabel('MA(5) ELO score', fontsize=12)\n",
    "plt.ylabel('Average star rating', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is (as expected!) a strong positive correlation between the average star rating and moving average ELO. Wines with higher 5-star ratings generally have higher MA ELO scores.\n",
    "\n",
    "The deviations from this correlation are more interesting. We can see that wines with an average rating of 3.5 stars can have MA ELO scores as low as 1000 or as high as 1700. These wines may be underserved by simple average star ratings, which can conceal their quality relative to other wines on the platform. The 2017 DeMorgenzon Chenin Blanc is a prime example: the right-most dot on the plot above, with a MA ELO that is much higher than its star rating would suggest. \n",
    "\n",
    "We can use a line of best fit (blue line) to indicate which wines are **outperforming** their average star rating. Wines to the right of this line have a higher MA ELO score than their average 5-point rating might suggest - and may therefore deserve a bit more love. A couple more examples:\n",
    "\n",
    "- **2018 Dão Reserva Branco by Cadiz from Dão, Portugal**: MA ELO of 2221, average star rating of 3.9\n",
    "- **2018 Klingenberg Spätburgunder by Weingut Stadt Klingenburg from Franken, Germany**: MA ELO of 1866, average star rating of 3.4\n",
    "- **2015 Serego Alighieri Poderi del Bello Ovile Toscana by Masi from Tuscany, Italy**: MA ELO of 1773, average star rating of 3.5 \n",
    "\n",
    "\n",
    "### Concluding Thoughts\n",
    "\n",
    "A word of caution before we write off star ratings. \n",
    "\n",
    "Star rating systems are easy to understand. ELO will be much less intuitive to the average user. It also has shortcomings that the 5-point rating scale does not have. Importantly, ELO does not treat a 1 vs 5 star rating any differently than a 3 vs 3.5 star rating. The magnitude of preferences is lost in favor of a scheme that is zero-sum and more simplistic. \n",
    "\n",
    "Still, we have demonstrated that ELO provides value in ways that an average 5-star rating cannot. The above is an exploratory exercise to show the potential of this metric, but only starts to scratch the surface. The sample size used (wine reviews by top 2500 Vivino users in the Netherlands) is very small. The definition of what constitutes a valid tournament (wines rated on the same day by the same user) is also very constrictive and could be relaxed to allow for a larger number of head-to-head comparisons between wines. With more data and by finetuning some of the underlying assumptions, ELO scores will become more robust and reliable. We may also want to develop an ELO algorithm with parameters that are purpose-built to rate wines, rather than using the exact system implemented in the world of chess. \n",
    "\n",
    "So how about this, for now: let's use ELO *in addition* to the average star rating. And discover some hidden gems such as the 2017 DeMorgenzon Reserve Chenin Blanc in the process! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine_elo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
